{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOr0Yrar/HBKyjREDm4p/d3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adrianwu8516/PersonalQuantResearch/blob/main/TQQQLab_ver1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 第一次嘗試，只用 TQQQ 數據跑模型，透過 ChatGPT vide coding\n",
        "\n",
        "\n",
        "# 來源：你的 TQQQ CSV 的 Google Drive file id（請確保「知道連結者可檢視」）\n",
        "SOURCE_DRIVE_FILE_ID = \"1QrHvtRjFOY0Hq7EzK3LmWH47FL7U91ej\"\n",
        "\n",
        "# 目的地：上傳結果 CSV 的 Google Drive folder id\n",
        "DESTINATION_FOLDER_ID = \"1QhdQskcFWmODDxxtRjcXzUTK0Y8ckcfh\"\n",
        "\n",
        "# 是否要做「隔日暴跌」預警（T-1 發警示）。True=做隔日，False=做當日\n",
        "PREDICT_NEXT_DAY = True\n",
        "\n",
        "# 極端下跌的門檻（標準差倍數）。2.0 是常見設定\n",
        "SIGMA = 2.0\n",
        "\n",
        "# 訓練/測試切割比例（時間序列切割）\n",
        "SPLIT_RATIO = 0.7"
      ],
      "metadata": {
        "id": "z24PqVjSIT-X"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install pandas numpy scikit-learn gdown yfinance"
      ],
      "metadata": {
        "id": "dX_2J1FoI55E"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tqqq_warning_models.py\n",
        "import argparse, os\n",
        "from typing import Tuple\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def download_drive_csv(file_id: str, out_path: str) -> str:\n",
        "    try:\n",
        "        import gdown\n",
        "    except ImportError as e:\n",
        "        raise RuntimeError(\"請先安裝 gdown：!pip install gdown\") from e\n",
        "    url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "    gdown.download(url, out_path, quiet=False)\n",
        "    if not os.path.exists(out_path) or os.path.getsize(out_path) == 0:\n",
        "        raise RuntimeError(\"下載失敗，請確認 Google Drive 檔案已設為『知道連結者可檢視』。\")\n",
        "    return out_path\n",
        "\n",
        "def load_prices(csv_path: str) -> pd.DataFrame:\n",
        "    df = pd.read_csv(csv_path)\n",
        "    df.columns = [c.strip().lower() for c in df.columns]\n",
        "    # 日期欄位\n",
        "    if 'date' in df.columns:\n",
        "        df['date'] = pd.to_datetime(df['date'])\n",
        "    elif 'timestamp' in df.columns:\n",
        "        df['date'] = pd.to_datetime(df['timestamp'])\n",
        "    else:\n",
        "        raise ValueError(\"需要 'Date' 或 'Timestamp' 欄位。\")\n",
        "    # 價格欄位\n",
        "    price_col = None\n",
        "    for c in ['adj close','adj_close','adjclose','close']:\n",
        "        if c in df.columns:\n",
        "            price_col = c; break\n",
        "    if price_col is None:\n",
        "        raise ValueError(\"需要 'Adj Close' 或 'Close' 欄位。\")\n",
        "    # 其他欄位（可選）\n",
        "    high_col = 'high' if 'high' in df.columns else None\n",
        "    low_col  = 'low'  if 'low'  in df.columns else None\n",
        "    vol_col  = 'volume' if 'volume' in df.columns else None\n",
        "\n",
        "    use = ['date', price_col]\n",
        "    if high_col: use.append(high_col)\n",
        "    if low_col:  use.append(low_col)\n",
        "    if vol_col:  use.append(vol_col)\n",
        "    df = df[use].copy().sort_values('date').reset_index(drop=True)\n",
        "    df.rename(columns={price_col:'price'}, inplace=True)\n",
        "    if high_col: df.rename(columns={high_col:'high'}, inplace=True)\n",
        "    if low_col:  df.rename(columns={low_col:'low'}, inplace=True)\n",
        "    if vol_col:  df.rename(columns={vol_col:'volume'}, inplace=True)\n",
        "    return df\n",
        "\n",
        "def build_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    out = df.copy()\n",
        "    out['ret'] = out['price'].pct_change()\n",
        "    for k in [1,2,3]:\n",
        "        out[f'ret_lag{k}'] = out['ret'].shift(k)\n",
        "    for w in [5,20,50]:\n",
        "        out[f'sma{w}'] = out['price'].rolling(w).mean()\n",
        "        out[f'vol{w}'] = out['ret'].rolling(w).std()\n",
        "    out['px_vs_sma20'] = out['price']/out['sma20'] - 1\n",
        "    out['px_vs_sma50'] = out['price']/out['sma50'] - 1\n",
        "    if 'volume' in out.columns:\n",
        "        out['vol_ratio5'] = out['volume']/out['volume'].rolling(5).mean()\n",
        "    else:\n",
        "        out['vol_ratio5'] = np.nan\n",
        "    if 'high' in out.columns and 'low' in out.columns:\n",
        "        out['range'] = (out['high']-out['low'])/out['price']\n",
        "    else:\n",
        "        out['range'] = np.nan\n",
        "    return out\n",
        "\n",
        "def make_labels(df_feat: pd.DataFrame, sigma=2.0):\n",
        "    std = df_feat['ret'].std(skipna=True)\n",
        "    thr = sigma * std\n",
        "    y = (df_feat['ret'] <= -thr).astype(int)   # 同日極端下跌（不做隔日）\n",
        "    return y, thr\n",
        "\n",
        "def prepare_xy(df_feat: pd.DataFrame, sigma=2.0):\n",
        "    y, thr = make_labels(df_feat, sigma=sigma)\n",
        "    feat_cols = [\n",
        "        'ret_lag1','ret_lag2','ret_lag3',\n",
        "        'sma5','sma20','sma50',\n",
        "        'vol5','vol20','vol50',\n",
        "        'px_vs_sma20','px_vs_sma50',\n",
        "        'vol_ratio5','range'\n",
        "    ]\n",
        "    X = df_feat[feat_cols]\n",
        "    m = X.notna().all(axis=1) & y.notna()\n",
        "    X = X[m]; y = y[m]\n",
        "    dates = df_feat.loc[m,'date']\n",
        "    rets  = df_feat.loc[m,'ret']\n",
        "    return X, y, dates, rets, thr\n",
        "\n",
        "def train_models(X_train, y_train):\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    # 高精度：balanced_subsample（偏少報警、高準度）\n",
        "    high = RandomForestClassifier(\n",
        "        n_estimators=200,\n",
        "        class_weight='balanced_subsample',\n",
        "        random_state=42, n_jobs=-1\n",
        "    )\n",
        "    # 低精度（高召回）：淺樹 + balanced（偏多報警、抓更多）\n",
        "    low = RandomForestClassifier(\n",
        "        n_estimators=200,\n",
        "        max_depth=4,\n",
        "        min_samples_leaf=5,\n",
        "        class_weight='balanced',\n",
        "        random_state=42, n_jobs=-1\n",
        "    )\n",
        "    high.fit(X_train, y_train)\n",
        "    low.fit(X_train, y_train)\n",
        "    return high, low\n",
        "\n",
        "def generate_warnings(model_name, pred, y_true, dates, rets):\n",
        "    tag = '高精度警示' if model_name=='high' else '低精度警示'\n",
        "    idx = np.where(pred==1)[0]\n",
        "    rows = []\n",
        "    for i in idx:\n",
        "        rows.append({\n",
        "            'Date': dates.iloc[i].strftime('%Y-%m-%d'),\n",
        "            'Model': tag,\n",
        "            'PredictedExtreme': int(pred[i]),\n",
        "            'ActualExtreme': int(y_true.iloc[i]),\n",
        "            'ReturnPct': rets.iloc[i]*100.0\n",
        "        })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(description='Detect same-day extreme down with two RandomForest models and output ONE CSV.')\n",
        "    parser.add_argument('--input', help='本機 CSV 路徑')\n",
        "    parser.add_argument('--drive-id', help='Google Drive 檔案 ID（需公開分享）')\n",
        "    parser.add_argument('--sigma', type=float, default=2.0, help='標準差倍數門檻，預設 2.0')\n",
        "    parser.add_argument('--split', type=float, default=0.7, help='時間切割比例，預設 0.7')\n",
        "    parser.add_argument('--output', required=True, help='輸出警示 CSV 路徑（單一檔案）')\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    if not args.input and not args.drive_id:\n",
        "        raise SystemExit(\"請提供 --input 或 --drive-id 其一。\")\n",
        "\n",
        "    tmp_path = None\n",
        "    if args.drive_id:\n",
        "        tmp_path = '/content/_drive_data.csv'\n",
        "        download_drive_csv(args.drive_id, tmp_path)\n",
        "        csv_path = tmp_path\n",
        "    else:\n",
        "        csv_path = args.input\n",
        "\n",
        "    df = load_prices(csv_path)\n",
        "    df_feat = build_features(df)\n",
        "    X, y, dates, rets, thr = prepare_xy(df_feat, sigma=args.sigma)\n",
        "\n",
        "    cut = int(len(X)*args.split)\n",
        "    X_train, X_test = X.iloc[:cut], X.iloc[cut:]\n",
        "    y_train, y_test = y.iloc[:cut], y.iloc[cut:]\n",
        "    dates_test = dates.iloc[cut:]\n",
        "    rets_test = rets.iloc[cut:]\n",
        "\n",
        "    high, low = train_models(X_train, y_train)\n",
        "    pred_high = high.predict(X_test)\n",
        "    pred_low  = low.predict(X_test)\n",
        "\n",
        "    warn_high = generate_warnings('high', pred_high, y_test, dates_test, rets_test)\n",
        "    warn_low  = generate_warnings('low',  pred_low,  y_test, dates_test, rets_test)\n",
        "    warnings_df = pd.concat([warn_high, warn_low], ignore_index=True).sort_values('Date').reset_index(drop=True)\n",
        "\n",
        "    os.makedirs(os.path.dirname(args.output), exist_ok=True)\n",
        "    warnings_df.to_csv(args.output, index=False)\n",
        "    print(\"Saved CSV to\", args.output)\n",
        "    if tmp_path and os.path.exists(tmp_path):\n",
        "        os.remove(tmp_path)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvl3Q7DfFoBW",
        "outputId": "7e99e1fc-2ea1-4061-c44f-4c48f39f9bd1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting tqqq_warning_models.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SOURCE_DRIVE_FILE_ID = \"1QrHvtRjFOY0Hq7EzK3LmWH47FL7U91ej\"  # 你的 TQQQ CSV（需「知道連結者可檢視」）\n",
        "OUTPUT_CSV = \"/content/tqqq_warnings_same_day.csv\"\n",
        "\n",
        "!python tqqq_warning_models.py \\\n",
        "  --drive-id {SOURCE_DRIVE_FILE_ID} \\\n",
        "  --sigma 2.0 \\\n",
        "  --split 0.7 \\\n",
        "  --output {OUTPUT_CSV}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-HGBAbdJSpH",
        "outputId": "49a95082-558b-4f0e-f386-58b1a5a41023"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QrHvtRjFOY0Hq7EzK3LmWH47FL7U91ej\n",
            "To: /content/_drive_data.csv\n",
            "\r  0% 0.00/846k [00:00<?, ?B/s]\r100% 846k/846k [00:00<00:00, 19.4MB/s]\n",
            "Saved CSV to /content/tqqq_warnings_same_day.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "import datetime as dt, os\n",
        "\n",
        "def upload_to_drive_folder(file_path, folder_id, new_name=None, mime_type=\"text/csv\"):\n",
        "    if not os.path.exists(file_path):\n",
        "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
        "\n",
        "    # 產生預設檔名（附時間戳）以免覆蓋\n",
        "    if new_name is None:\n",
        "        stamp = dt.datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
        "        base = os.path.splitext(os.path.basename(file_path))[0]\n",
        "        new_name = f\"{base}_{stamp}.csv\"\n",
        "\n",
        "    service = build(\"drive\", \"v3\")\n",
        "    body = {\"name\": new_name, \"parents\": [folder_id]}\n",
        "    media = MediaFileUpload(file_path, mimetype=mime_type, resumable=True)\n",
        "\n",
        "    file = service.files().create(\n",
        "        body=body, media_body=media, fields=\"id, webViewLink\"\n",
        "    ).execute()\n",
        "\n",
        "    print(f\"Uploaded: {file['webViewLink']}  (fileId={file['id']})\")\n",
        "    return file\n",
        "\n",
        "# ---- 使用範例（只上傳同日輸出）----\n",
        "# 確保你在前面的步驟有設定：\n",
        "# OUT_SAME_DAY = \"/content/tqqq_warnings_same_day.csv\"\n",
        "# DESTINATION_FOLDER_ID = \"<你的 folder id>\"\n",
        "if os.path.exists(OUT_SAME_DAY):\n",
        "    upload_to_drive_folder(\n",
        "        OUT_SAME_DAY,\n",
        "        DESTINATION_FOLDER_ID,\n",
        "        new_name=None  # 不指定則自動加上時間戳\n",
        "    )\n",
        "else:\n",
        "    print(f\"Output not found: {OUT_SAME_DAY}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEoC6I2CJYOQ",
        "outputId": "6b3c0e5e-5c38-4dbb-af3b-cad62b575f4f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploaded: https://drive.google.com/file/d/1KmTFdc1io0pum2B5_TKwGiLYGErw9VPR/view?usp=drivesdk  (fileId=1KmTFdc1io0pum2B5_TKwGiLYGErw9VPR)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!grep -n \"predict-\" tqqq_warning_models.py || true\n",
        "!sed -i 's/args\\.predict-full/args.predict_full/g' tqqq_warning_models.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lhdLXriJhIQ",
        "outputId": "3e1f5039-5aab-4ec4-ad32-05b51a177a48"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157:    parser.add_argument('--predict-full', action='store_true', help='訓練後對「全期間」都做推論並輸出警示（含訓練段與測試段）')\n",
            "195:    if args.predict-full:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_vxQYaFAiD2k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}